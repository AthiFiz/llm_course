{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Ways of Using LLM APIs\n",
    "\n",
    "### 01. OpenAI APIs\n",
    "    - You can use OpenAI APIs directly by using OpenAI API key\n",
    "    - OpenAI keys will available in your OpenAI account\n",
    "\n",
    "### 02. Together AI APIs\n",
    "    - Instead of using OpenAI API key, you can use Together AI API key\n",
    "    - Together AI has hosted more than 100+ Models in both closed and open source\n",
    "\n",
    "### 03. Azure APIs\n",
    "    - You can access OpenAI APIs through Azurem instead of using OpenAI API directly\n",
    "    - This is the best way to use OpenAI APIs in production\n",
    "    - It will secure your data you input via prompting\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml, together\n",
    "from openai import OpenAI, ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credential.yaml') as f:\n",
    "    credentials = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "os.environ['TOGETHER_AI_API'] = credentials['TOGETHER_AI_API']\n",
    "os.environ['OPENAI_API_KEY'] = credentials['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Basic Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01. Using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_model(USER_MESSAGE):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=25\n",
    "    )\n",
    "    return str(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02. Using Together AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together.api_key = os.environ[\"TOGETHER_AI_API\"]\n",
    "\n",
    "# list available models and descriptons\n",
    "models = together.Models.list()\n",
    "for m in models:\n",
    "    print(m['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together.Models.start(\"togethercomputer/llama-2-13b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_model_together(USER_MESSAGE):\n",
    "    output = together.Complete.create(\n",
    "                                    USER_MESSAGE,\n",
    "                                    model=\"togethercomputer/llama-2-13b-chat\",\n",
    "                                    max_tokens=20,\n",
    "                                    temperature=0,\n",
    "                                    )\n",
    "    text = output['output']['choices'][0]['text'].replace('\\n', '   ').strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current president of the United States is Joe Biden. He was inaugurated on January'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model_together('Who is the president of the United States?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_model(USER_MESSAGE):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=100\n",
    "    )\n",
    "    return str(response.choices[0].message.content)\n",
    "\n",
    "# def completion_model(USER_MESSAGE):\n",
    "#     response = client.chat.completions.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful sentiment analyzer. Classify the text into neutral, negative or positive.\"},\n",
    "#         {\"role\": \"user\", \"content\": USER_MESSAGE}\n",
    "#     ],\n",
    "#     temperature=0,\n",
    "#     max_tokens=10\n",
    "#     )\n",
    "#     return str(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model('''\n",
    "Classify the text into neutral, negative or positive. \n",
    "\n",
    "Text: I think the vacation is okay.\n",
    "Sentiment:\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_model(USER_MESSAGE):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=10\n",
    "    )\n",
    "    return str(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model('''\n",
    "                 \n",
    "Classify the TEXT into neutral, negative or positive. use below examples for few shots. only return neutral, negative or positive\n",
    "                 \n",
    "This is awesome! // Positive\n",
    "This is bad! // Negative\n",
    "That movie was ok. // Neutral\n",
    "                 \n",
    "\n",
    "The day was not nice.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) COT Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_model(USER_MESSAGE):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=1000\n",
    "    )\n",
    "    return str(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29 fruits'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model('''               \n",
    "I went to the market and bought 10 apples. \n",
    "I gave 2 apples to the neighbor and 2 to the repairman.\n",
    "I then went and bought 5 more apples and ate 1.             \n",
    "How many apples did I remain with if I neglect the one I ate? Do not include the method of solving the problem.\n",
    "                \n",
    "Answer : 11 Apples \n",
    "                 \n",
    "I went to the shop with 10 bags. each bag can store 3 fruits \n",
    "I bought fruits until all the bags were full. I gave 5 fruits to my friend and ate 1.\n",
    "How many fruits did I remain with if I neglect the one I ate? Do not include the method of solving the problem. \n",
    "\n",
    "Answer :\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You started with 10 bags, and each bag can store 3 fruits. So you had a total of 10 x 3 = 30 fruits.\n",
      "After giving 5 fruits to your friend, you had 30 - 5 = 25 fruits.\n",
      "You then ate 1 fruit, but since we are neglecting it, you remained with 25 fruits.\n"
     ]
    }
   ],
   "source": [
    "print(completion_model('''               \n",
    "I went to the market and bought 10 apples. \n",
    "I gave 2 apples to the neighbor and 2 to the repairman.\n",
    "I then went and bought 5 more apples and ate 1.             \n",
    "How many apples did I remain with if I neglect the one I ate? Do not include the method of solving the problem.\n",
    "                \n",
    "Answer : I started with 10 apples. \n",
    "         After giving 2 to the neighbor and 2 to the repairman. 10 - 2 - 2 = 6.\n",
    "         I bought 5 more apples. 6 + 5 = 11. I ate 1 but since we are neglecting it, I remained with 11 apples.\n",
    "                 \n",
    "I went to the shop with 10 bags. each bag can store 3 fruits \n",
    "I bought fruits until all the bags were full. I gave 5 fruits to my friend and ate 1.\n",
    "How many fruits did I remain with if I neglect the one I ate? Do not include the method of solving the problem. \n",
    "\n",
    "Answer :\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) Self-Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_model(USER_MESSAGE):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE}\n",
    "    ],\n",
    "    temperature=0.9,\n",
    "    max_tokens=100\n",
    "    )\n",
    "    return str(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You started with 10 bags, each bag can store 3 fruits. So you had 10 x 3 = 30 fruits at the beginning.\n",
      "You filled all the bags with fruits, so you used all 30 fruits.\n",
      "Then you gave 5 fruits to your friend and ate 1, so you used 5 + 1 = 6 fruits.\n",
      "Since we are neglecting the one you ate, you remained with 30 - 6 = 24 fruits.\n"
     ]
    }
   ],
   "source": [
    "print(completion_model('''               \n",
    "I went to the market and bought 10 apples. \n",
    "I gave 2 apples to the neighbor and 2 to the repairman.\n",
    "I then went and bought 5 more apples and ate 1.             \n",
    "How many apples did I remain with if I neglect the one I ate? Do not include the method of solving the problem.\n",
    "                \n",
    "Answer : I started with 10 apples. \n",
    "         After giving 2 to the neighbor and 2 to the repairman. 10 - 2 - 2 = 6.\n",
    "         I bought 5 more apples. 6 + 5 = 11. I ate 1 but since we are neglecting it, I remained with 11 apples.\n",
    "                 \n",
    "I went to the shop with 10 bags. each bag can store 3 fruits \n",
    "I bought fruits until all the bags were full. I gave 5 fruits to my friend and ate 1.\n",
    "How many fruits did I remain with if I neglect the one I ate? Do not include the method of solving the problem. \n",
    "\n",
    "Answer :\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You had 10 bags and each bag can store 3 fruits, so you had a total capacity of 10 bags * 3 fruits/bag = 30 fruits.\n",
      "You filled all the bags with fruits, so you had 30 fruits.\n",
      "You gave 5 fruits to your friend, so you had 30 fruits - 5 fruits = 25 fruits left.\n",
      "You ate 1 fruit, but since we are neglecting it, you remained with 25 fruits.\n"
     ]
    }
   ],
   "source": [
    "print(completion_model('''               \n",
    "I went to the market and bought 10 apples. \n",
    "I gave 2 apples to the neighbor and 2 to the repairman.\n",
    "I then went and bought 5 more apples and ate 1.             \n",
    "How many apples did I remain with if I neglect the one I ate? Do not include the method of solving the problem.\n",
    "                \n",
    "Answer : I started with 10 apples. \n",
    "         After giving 2 to the neighbor and 2 to the repairman. 10 - 2 - 2 = 6.\n",
    "         I bought 5 more apples. 6 + 5 = 11. I ate 1 but since we are neglecting it, I remained with 11 apples.\n",
    "                 \n",
    "I went to the shop with 10 bags. each bag can store 3 fruits \n",
    "I bought fruits until all the bags were full. I gave 5 fruits to my friend and ate 1.\n",
    "How many fruits did I remain with if I neglect the one I ate? Do not include the method of solving the problem. \n",
    "\n",
    "Answer :\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E) ToT Prompting\n",
    "\n",
    "Imagine three different experts are answering this question. </br>\n",
    "All experts will write down 1 step of their thinking, </br>\n",
    "then share it with the group. </br>\n",
    "Then all experts will go on to the next step, etc. </br>\n",
    "If any expert realises they're wrong at any point then they leave. </br>\n",
    "The question is..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
