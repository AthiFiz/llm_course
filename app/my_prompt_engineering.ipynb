{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, yaml, together\n",
    "from openai import OpenAI, ChatCompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credential.yaml\") as f:\n",
    "    credentials = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "os.environ[\"TOGETHER_AI_API\"] = credentials[\"TOGETHER_AI_API\"]\n",
    "os.environ[\"OPENAI_API_KEY\"] = credentials[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_model(USER_MESSAGE):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "            {\"role\": \"user\", \"content\": USER_MESSAGE}\n",
    "        ],\n",
    "        temperature=0.9, #create randomness in answering. gives the same answer in different shades \n",
    "        max_tokens=100)\n",
    "    return str(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As of my knowledge update in September 2021, the President of Sri Lanka is Gotabaya Rajapaksa. He assumed office on November 18, 2019. Please note that political positions can change, so it's always a\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model(\"Who is the president of Sri Lanka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "together.api_key = os.environ[\"TOGETHER_AI_API\"]\n",
    "\n",
    "models = together.Models.list()\n",
    "for m in models:\n",
    "    print(m[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# together.Models.start(\"togethercomputer/llama-2-13b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = []\n",
    "together.api_key = os.environ[\"TOGETHER_AI_API\"]\n",
    "\n",
    "models = together.Models.list()\n",
    "for m in models:\n",
    "    model_name_list.append(m[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"togethercomputer/llama-2-13b-chat\" in model_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text is positive.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model('''\n",
    "Classify the text into neutral, negative or positive\n",
    "Text : I think the vaction is good \n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_model_one(USER_MESSAGE):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful sentiment analyzer. Classify the text into neutral, negative or positive.\"},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=10\n",
    "    )\n",
    "    return str(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are many good movies out there, it really depends on your personal preferences. Some popular choices among'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model(\"Good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text can be classified as neutral.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model('''\n",
    "Classify the following text into positive, neutral or negative\n",
    "Text: Good Movie but duration is lengthy\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model('''\n",
    "Classify the following text into positive, neutral or negative\n",
    "Text: Good Movie but duration is lengthy\n",
    "Sentiment:\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model_one('Good Movie but duration is lengthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This statement can be classified as neutral.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model('''\n",
    "                 \n",
    "Classify the TEXT into neutral, negative or positive. use below examples for few shots.\n",
    "                 \n",
    "This is awesome! - its Positive\n",
    "This is bad! - its Negative\n",
    "That movie was ok -  its Neutral\n",
    "                 \n",
    "\n",
    "I am lazy but efficient\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29 fruits'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_model('''               \n",
    "I went to the market and bought 10 apples. \n",
    "I gave 2 apples to the neighbor and 2 to the repairman.\n",
    "I then went and bought 5 more apples and ate 1.             \n",
    "How many apples did I remain with if I neglect the one I ate? Do not include the method of solving the problem.\n",
    "                \n",
    "Answer : 11 Apples \n",
    "                 \n",
    "I went to the shop with 10 bags. each bag can store 3 fruits \n",
    "I bought fruits until all the bags were full. I gave 5 fruits to my friend and ate 1.\n",
    "How many fruits did I remain with if I neglect the one I ate? Do not include the method of solving the problem. \n",
    "\n",
    "Answer :\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You had 10 bags, and each bag can store 3 fruits. So you had a total of 10 x 3 = 30 fruits.\n",
      "You gave 5 fruits to your friend, so you had 30 - 5 = 25 fruits left.\n",
      "You also ate 1 fruit, but since we are neglecting it, you remained with 25 fruits.\n"
     ]
    }
   ],
   "source": [
    "print(completion_model('''               \n",
    "I went to the market and bought 10 apples. \n",
    "I gave 2 apples to the neighbor and 2 to the repairman.\n",
    "I then went and bought 5 more apples and ate 1.             \n",
    "How many apples did I remain with if I neglect the one I ate? Do not include the method of solving the problem.\n",
    "                \n",
    "Answer : I started with 10 apples. \n",
    "         After giving 2 to the neighbor and 2 to the repairman. 10 - 2 - 2 = 6.\n",
    "         I bought 5 more apples. 6 + 5 = 11. I ate 1 but since we are neglecting it, I remained with 11 apples.\n",
    "                 \n",
    "I went to the shop with 10 bags. each bag can store 3 fruits \n",
    "I bought fruits until all the bags were full. I gave 5 fruits to my friend and ate 1.\n",
    "How many fruits did I remain with if I neglect the one I ate? Do not include the method of solving the problem. \n",
    "\n",
    "Answer :\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
